{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b07f9414",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.metrics import binary_crossentropy\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "\n",
    "\n",
    "def unstack(tensor, axis=3, image_size=512):\n",
    "    unstacked_tensors = []\n",
    "    for i, t in enumerate(tf.unstack(tensor, axis=axis)):\n",
    "        unstacked_tensors.append(tf.reshape(t, [-1, image_size, image_size, 1]))\n",
    "    return unstacked_tensors\n",
    "\n",
    "\n",
    "\n",
    "def gt_loss(y_true, y_pred, max_degree=6, image_size=512):\n",
    "    y_true = unstack(y_true)\n",
    "    y_pred = unstack(y_pred)\n",
    "    \n",
    "    batch_size = tf.shape(y_true[0])[0]\n",
    "\n",
    "    soft_mask = tf.reshape(y_true[0], (batch_size, image_size, image_size))\n",
    "    #  Crossentropy loss for vertex channel\n",
    "    pv_loss = tf.reduce_mean(binary_crossentropy(y_true[0], y_pred[0]))\n",
    "    pe_loss = 0\n",
    "    for i in range(max_degree):\n",
    "        pe_crossentropy = binary_crossentropy(y_true[1 + 3*i], y_pred[1 + 3*i])\n",
    "        # Apply only to keypoints!\n",
    "        pe_loss += tf.reduce_mean(tf.multiply(soft_mask, pe_crossentropy))\n",
    "    direction_loss = 0\n",
    "    for i in range(max_degree):\n",
    "        v1 = tf.concat(y_true[2 + 3*i:4 + 3*i], axis=3)\n",
    "        v2 = tf.concat(y_pred[2 + 3*i:4 + 3*i], axis=3)\n",
    "        # Apply only to keypoints!\n",
    "        direction_loss += tf.reduce_mean(tf.multiply(y_true[0], tf.square(v2 - v1)))\n",
    "    return pv_loss + 10 * pe_loss + 1000 * direction_loss\n",
    "\n",
    "\n",
    "def conv_block(inputs, filters):\n",
    "    x = layers.Conv2D(filters, 3, padding='same')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(filters, 3, padding='same')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def decoder_block(inputs, skip_features, filters):\n",
    "    x = layers.Conv2DTranspose(filters, (2, 2), strides=2, padding='same')(inputs)\n",
    "    x = layers.Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, filters)\n",
    "    return x\n",
    "\n",
    "\n",
    "class GteOutput(layers.Layer):\n",
    "    def __init__(self, max_degree=6, *args, **kwargs):\n",
    "        super(GteOutput, self).__init__(*args, **kwargs)\n",
    "        self.max_degree = max_degree\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        outputs = unstack(inputs)\n",
    "        outputs[0] = tf.math.sigmoid(outputs[0])\n",
    "        for i in range(self.max_degree):\n",
    "            outputs[1 + 3*i] = tf.math.sigmoid(outputs[1 + 3*i])\n",
    "        return tf.concat(outputs, axis=3)\n",
    "\n",
    "    \n",
    "def resnet50_unet(input_shape, max_degree=6):\n",
    "    inputs = layers.Input(shape=input_shape, name='input')\n",
    "\n",
    "    # Pre-trained resnet50\n",
    "    resnet50 = ResNet50(include_top=False, weights='imagenet', input_tensor=inputs)\n",
    "\n",
    "    # Skip connections\n",
    "    s1 = resnet50.get_layer('input').output                   # x1\n",
    "    s2 = resnet50.get_layer('conv1_relu').output              # x2\n",
    "    s3 = resnet50.get_layer('conv2_block3_out').output        # x4\n",
    "    s4 = resnet50.get_layer('conv3_block4_out').output        # x8\n",
    "\n",
    "    # Bridge\n",
    "    b1 = resnet50.get_layer('conv4_block6_out').output\n",
    "\n",
    "    # Decoder blocks\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "    \n",
    "    raw_outputs = layers.Conv2D(1 + 3 * max_degree, kernel_size=(3, 3), padding='same', activation='linear', name='raw_output')(d4)\n",
    "    \n",
    "    outputs = GteOutput(max_degree=max_degree, name=\"outputs\")(raw_outputs)\n",
    "    \n",
    "    return Model(inputs, outputs, name='resnet50_unet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7e4df0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "vegas = pd.read_csv('data/tiles_Vegas.csv', index_col=0)\n",
    "paris = pd.read_csv('data/tiles_Paris.csv', index_col=0)\n",
    "shanghai = pd.read_csv('data/tiles_Shanghai.csv', index_col=0)\n",
    "khartoum = pd.read_csv('data/tiles_Khartoum.csv', index_col=0)\n",
    "\n",
    "df = pd.concat([vegas, paris, shanghai, khartoum]).reset_index()\n",
    "df\n",
    "\n",
    "df_20cities = pd.read_csv('data/20cities_dataset.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cfc8337",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-12 09:12:27.250145: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-12 09:12:39.616564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13579 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:8b:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from gte import GraphTensorEncoder\n",
    "\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def to_int(u):\n",
    "    return int(u[0]), int(u[1])\n",
    "\n",
    "\n",
    "def load_graph(path):\n",
    "    graph = defaultdict(set)\n",
    "    for u, neighbours in pickle.load(open(path, 'rb')).items():\n",
    "        u = to_int(u)\n",
    "        for v in neighbours:\n",
    "            graph[u].add(to_int(v))\n",
    "    return graph\n",
    "\n",
    "\n",
    "class Reader:\n",
    "    def __init__(self, df, image_size):\n",
    "        self.encoder = GraphTensorEncoder(max_degree=6, image_size=image_size[0], d=25)\n",
    "        self.df = df\n",
    "        self.image_size = image_size\n",
    "        \n",
    "    def __call__(self):\n",
    "        for index, row in self.df.iterrows():\n",
    "            tile = cv2.imread(row['tile'])\n",
    "            graph = load_graph(row['graph'])\n",
    "            gt = self.encoder.encode(graph)\n",
    "            yield tile, gt\n",
    "            \n",
    "image_size = (512, 512)\n",
    "dataset = tf.data.Dataset.from_generator(Reader(df_20cities, image_size),\n",
    "                                        output_signature=(\n",
    "                                            tf.TensorSpec(shape=image_size+(3,), dtype=tf.float32),\n",
    "                                            tf.TensorSpec(shape=image_size+(19,), dtype=tf.float32)\n",
    "                                        )).cache()\\\n",
    "                                          .batch(8)\\\n",
    "                                          .repeat()\\\n",
    "                                          .prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f923e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-12 09:12:59.735047: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8200\n",
      "2022-06-12 09:13:07.961578: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2022-06-12 09:13:25.349098: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.93GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n",
      "2022-06-12 09:13:25.349174: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.93GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/500 [=============>................] - ETA: 7:00 - loss: 3.1164"
     ]
    }
   ],
   "source": [
    "model = resnet50_unet((512, 512, 3), max_degree=6)\n",
    "\n",
    "scheduler = tf.keras.optimizers.schedules.ExponentialDecay(1e-2, 3000, 0.1)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=gt_loss)\n",
    "\n",
    "model.fit(dataset, epochs=5, steps_per_epoch=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b768fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = GraphTensorEncoder(max_degree=6, image_size=512, d=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4aa187",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = []\n",
    "for tile, graph in Reader(df_20cities.sample(20), image_size):\n",
    "    tiles.append(tile)\n",
    "tiles = np.array(tiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba88991b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
